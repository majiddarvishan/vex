#pragma once

#include <vex/networking/common.hpp>
#include <vex/networking/net/detail/ring_buffer.hpp>
#include <vex/networking/pdu.hpp>

#include <boost/asio.hpp>
#include <boost/asio/bind_executor.hpp>
#include <boost/asio/strand.hpp>

#include <algorithm>
#include <array>
#include <atomic>
#include <cstring>
#include <iostream>
#include <memory>
#include <memory_resource>
#include <optional>
#include <span>
#include <utility>
#include <variant>
#include <vector>

// Platform socket option includes for keepalive
#if defined(__linux__) || defined(__APPLE__) || defined(__unix__)
    #include <netinet/in.h>
    #include <netinet/tcp.h>
    #include <sys/socket.h>
#endif

namespace pa::pinex
{

static void enable_keepalive(boost::asio::ip::tcp::socket& socket, uint16_t inactivity_timeout)
{
    boost::system::error_code ec;
    socket.set_option(boost::asio::socket_base::keep_alive(true), ec);

    if (ec) {
        std::cerr << "Warning: Failed to enable SO_KEEPALIVE: " << ec.message() << std::endl;
    }

#if defined(__linux__)
    int idle = static_cast<int>(inactivity_timeout);
    int interval = 10;
    int count = 5;
    int fd = static_cast<int>(socket.native_handle());

    if (::setsockopt(fd, SOL_SOCKET, SO_KEEPALIVE, &idle, sizeof(idle)) != 0) {
        std::cerr << "Warning: SO_KEEPALIVE setsockopt failed" << std::endl;
    }
    if (::setsockopt(fd, IPPROTO_TCP, TCP_KEEPIDLE, &idle, sizeof(idle)) != 0) {
        std::cerr << "Warning: TCP_KEEPIDLE setsockopt failed" << std::endl;
    }
    if (::setsockopt(fd, IPPROTO_TCP, TCP_KEEPINTVL, &interval, sizeof(interval)) != 0) {
        std::cerr << "Warning: TCP_KEEPINTVL setsockopt failed" << std::endl;
    }
    if (::setsockopt(fd, IPPROTO_TCP, TCP_KEEPCNT, &count, sizeof(count)) != 0) {
        std::cerr << "Warning: TCP_KEEPCNT setsockopt failed" << std::endl;
    }
#elif defined(__APPLE__)
    int idle = static_cast<int>(inactivity_timeout);
    int fd = static_cast<int>(socket.native_handle());
    if (::setsockopt(fd, IPPROTO_TCP, TCP_KEEPALIVE, &idle, sizeof(idle)) != 0) {
        std::cerr << "Warning: TCP_KEEPALIVE setsockopt failed" << std::endl;
    }
#endif
}

using request = std::variant<std::monostate, bind_request, stream_request>;
using response = std::variant<std::monostate, bind_response, stream_response>;

// Session statistics for monitoring
struct session_stats {
    std::atomic<uint64_t> bytes_sent{0};
    std::atomic<uint64_t> bytes_received{0};
    std::atomic<uint64_t> pdus_sent{0};
    std::atomic<uint64_t> pdus_received{0};
    std::atomic<uint64_t> ring_overflows{0};
    std::atomic<uint64_t> fallback_sends{0};
};

// Configuration flag - define NETWORKING_MULTI_THREADED for multi-threaded
#ifdef NETWORKING_MULTI_THREADED
    #define PINEX_EXECUTOR_TYPE boost::asio::any_io_executor
    #define PINEX_BIND_EXECUTOR(strand, handler) handler
#else
    #define PINEX_EXECUTOR_TYPE boost::asio::strand<boost::asio::any_io_executor>
    #define PINEX_BIND_EXECUTOR(strand, handler) boost::asio::bind_executor(strand, handler)
#endif

class session : public std::enable_shared_from_this<session>
{
  public:
    // user-provided handlers
    std::function<void(std::shared_ptr<session>, std::optional<std::string>)> close_handler;
    std::function<void(request&&, uint32_t)> request_handler;
    std::function<void(response&&, uint32_t, command_status)> response_handler;
    std::function<void()> send_buf_available_handler;
    std::function<void(const std::string&, command_id, std::span<const uint8_t>)> deserialization_error_handler;

  private:
    enum class state { open, unbinding, close };
    enum class receiving_state { receiving, pending_pause, paused };

    static constexpr size_t header_length{10};
    static constexpr uint32_t max_command_length{10 * 1024 * 1024}; // 10MB
    static constexpr std::size_t max_send_chunk{256 * 1024}; // Increased from 128KB
    static constexpr std::size_t max_pending_send_buf{50 * 1024 * 1024}; // 50MB limit for fallback buffer

    state state_{state::open};
    receiving_state receiving_state_{receiving_state::paused};
    uint32_t sequence_number_{0};
    int inactivity_counter_{};

    // asio primitives
    boost::asio::ip::tcp::socket socket_;
    PINEX_EXECUTOR_TYPE strand_;

    // receive ring buffer
    detail::ring_buffer<uint8_t, 1024 * 1024> receive_buf_;

    // send ring buffer and fallback
    detail::ring_buffer<uint8_t, 1024 * 1024> send_ring_;
    std::vector<uint8_t> pending_send_buf_;
    std::vector<uint8_t> writing_send_buf_;
    size_t send_buf_threshold_{1024 * 1024};

    // PMR allocator for temporary buffers (eliminates heap allocations)
    std::array<std::byte, 64 * 1024> monotonic_buffer_;
    std::pmr::monotonic_buffer_resource mbr_;
    std::pmr::vector<uint8_t> body_reuse_buf_;

    // Statistics
    session_stats stats_;

    // Track if async send is in progress
    bool send_in_progress_{false};

  public:
    explicit session(boost::asio::io_context* /*io_context*/, boost::asio::ip::tcp::socket socket)
      : socket_(std::move(socket)),
        strand_(socket_.get_executor()),
        mbr_(monotonic_buffer_.data(), monotonic_buffer_.size()),
        body_reuse_buf_(&mbr_)
    {
        pending_send_buf_.reserve(8192);
        writing_send_buf_.reserve(8192);
        body_reuse_buf_.reserve(8192);
    }

    session(const session&) = delete;
    session& operator=(const session&) = delete;
    session(session&&) = delete;
    session& operator=(session&&) = delete;
    ~session() = default;

    void start()
    {
        enable_keepalive(socket_, /*inactivity_timeout=*/60);
        resume_receiving();
    }

    std::tuple<std::string, uint16_t> remote_endpoint() const
    {
        auto ep = socket_.remote_endpoint();
        return {ep.address().to_string(), ep.port()};
    }

    bool is_open() const { return state_ == state::open; }

    const session_stats& get_stats() const { return stats_; }

    void unbind()
    {
        if (state_ == state::open)
        {
            state_ = state::unbinding;
            send_command(command_id::unbind_req);
        }
    }

    template<typename PDU>
    void send_response(const PDU& pdu, uint32_t sequence_number, command_status command_status)
    {
        static_assert(detail::is_response<PDU>, "PDU isn't a response");
        send_impl(pdu, sequence_number, command_status);
    }

    template<typename PDU>
    uint32_t send_request(const PDU& pdu)
    {
        static_assert(!detail::is_response<PDU>, "PDU isn't a request");
        auto sequence_number = next_sequence_number();
        send_impl(pdu, sequence_number, command_status::rok);
        return sequence_number;
    }

    void set_send_buf_threshold(size_t s) { send_buf_threshold_ = s; }

    bool is_send_buf_above_threshold() const {
        return (send_ring_.space_remaining() < send_buf_threshold_) || (!pending_send_buf_.empty());
    }

    // Check if we can send without blocking/queueing to fallback buffer
    bool can_send_without_blocking() const {
        return send_ring_.space_remaining() > send_buf_threshold_ && pending_send_buf_.empty();
    }

    void pause_receiving()
    {
        if (receiving_state_ == receiving_state::receiving)
            receiving_state_ = receiving_state::pending_pause;
    }

    void resume_receiving()
    {
        auto prev = std::exchange(receiving_state_, receiving_state::receiving);
        if (prev == receiving_state::paused)
            boost::asio::post(strand_, [self = shared_from_this()] { self->do_receive(); });
    }

  private:
    void close(const std::string& reason)
    {
        boost::asio::post(strand_, [wptr = weak_from_this(), reason]() {
            if (auto self = wptr.lock())
            {
                if (self->state_ == state::close) return;

                self->pause_receiving();

                std::optional<std::string> err;
                if (self->state_ == state::open)
                    err = reason;

                boost::system::error_code ec;
                self->socket_.shutdown(boost::asio::ip::tcp::socket::shutdown_both, ec);
                self->socket_.close(ec);
                self->state_ = state::close;

                // Copy handler before clearing to avoid use-after-free
                auto close_copy = std::move(self->close_handler);
                self->request_handler = {};
                self->response_handler = {};
                self->send_buf_available_handler = {};
                self->deserialization_error_handler = {};
                self->close_handler = {};

                if (close_copy) close_copy(self, err);
            }
        });
    }

    uint32_t next_sequence_number()
    {
        if (++sequence_number_ > 0x7FFFFFFF) sequence_number_ = 1;
        return sequence_number_;
    }

    // ---------------- Receive ----------------
    void do_receive()
    {
        while (true)
        {
            if (receiving_state_ != receiving_state::receiving)
                break;

            if (receive_buf_.size() < header_length)
                break;

            // Optimization: Try to read header directly if contiguous
            std::array<std::span<const uint8_t>, 2> header_spans{};
            size_t header_filled = receive_buf_.dequeue_scatter_gather(header_spans, header_length, /*peek_only=*/true);

            if (header_filled < header_length) [[unlikely]]
                break;

            uint32_t command_length, seq_num;
            command_id cmd_id;
            command_status cmd_status;

            // Fast path: header is contiguous
            if (header_spans[0].size() >= header_length) {
                auto [cl, ci, cs, sn] = deserialize_header(header_spans[0].subspan(0, header_length));
                command_length = cl;
                cmd_id = ci;
                cmd_status = cs;
                seq_num = sn;
            } else {
                // Slow path: copy header
                uint8_t header_buf[header_length];
                size_t copied = 0;
                for (auto s : header_spans)
                {
                    if (copied >= header_length) break;
                    auto to_copy = std::min(s.size(), header_length - copied);
                    if (to_copy > 0)
                    {
                        std::memcpy(header_buf + copied, s.data(), to_copy);
                        copied += to_copy;
                    }
                }
                auto [cl, ci, cs, sn] = deserialize_header(std::span<const uint8_t>(header_buf, header_length));
                command_length = cl;
                cmd_id = ci;
                cmd_status = cs;
                seq_num = sn;
            }

            if (command_length < header_length) [[unlikely]] {
                close("Invalid command_length");
                return;
            }
            if (command_length > max_command_length) [[unlikely]] {
                close("Command too large");
                return;
            }
            if (receive_buf_.size() < command_length)
                break;

            // Get body (skip header)
            size_t body_size = command_length - header_length;

            // Reset PMR buffer for this PDU
            mbr_.release();
            body_reuse_buf_.clear();

            if (body_size > 0) {
                // Peek at full PDU
                std::array<std::span<const uint8_t>, 2> pdu_spans{};
                size_t pdu_filled = receive_buf_.dequeue_scatter_gather(pdu_spans, command_length, /*peek_only=*/true);

                if (pdu_filled < command_length) [[unlikely]]
                    break;

                // Extract body efficiently
                body_reuse_buf_.reserve(body_size);
                size_t offset = 0;
                size_t body_copied = 0;

                for (auto s : pdu_spans)
                {
                    if (body_copied >= body_size) break;

                    if (offset + s.size() > header_length)
                    {
                        size_t body_off = (offset >= header_length) ? 0 : (header_length - offset);
                        size_t available = s.size() - body_off;
                        size_t need = body_size - body_copied;
                        size_t take = std::min(available, need);

                        if (take > 0)
                        {
                            const uint8_t* src = s.data() + static_cast<std::ptrdiff_t>(body_off);
                            body_reuse_buf_.insert(body_reuse_buf_.end(), src, src + take);
                            body_copied += take;
                        }
                    }
                    offset += s.size();
                }
            }

            std::span<const uint8_t> body_span(body_reuse_buf_.data(), body_reuse_buf_.size());

            if (is_response(cmd_id))
                consume_response_pdu(cmd_id, cmd_status, seq_num, body_span);
            else
                consume_request_pdu(cmd_id, cmd_status, seq_num, body_span);

            // Consume the PDU immediately after processing
            receive_buf_.consume(command_length);
            stats_.bytes_received.fetch_add(command_length, std::memory_order_relaxed);
            stats_.pdus_received.fetch_add(1, std::memory_order_relaxed);
        }

        if (receiving_state_ == receiving_state::pending_pause)
        {
            receiving_state_ = receiving_state::paused;
            return;
        }

        // Prepare to receive more data
        auto want = std::min<std::size_t>(receive_buf_.capacity() - receive_buf_.size(), 64 * 1024);
        if (want == 0) [[unlikely]]
        {
            close("receive buffer full");
            return;
        }

        auto handler = [this, wptr = weak_from_this()](std::error_code ec, size_t received) {
            if (auto self = wptr.lock())
            {
                if (ec) return self->close(ec.message());
                self->receive_buf_.commit(received);
                if (self->state_ == state::open) self->inactivity_counter_ = 0;
                self->do_receive();
            }
        };

        socket_.async_receive(
            receive_buf_.prepare(want),
            PINEX_BIND_EXECUTOR(strand_, handler));
    }

    void consume_response_pdu(command_id command_id, command_status command_status, uint32_t sequence_number, std::span<const uint8_t> buf)
    {
        response resp;
        try
        {
            switch (command_id)
            {
                case command_id::enquire_link_resp: break;
                case command_id::unbind_resp: close("unbind_resp received"); return;
                case command_id::bind_resp: resp = deserialize<bind_response>(buf, bind_type::bi_direction); break;
                case command_id::stream_resp: resp = deserialize<stream_response>(buf); break;
                default: throw std::logic_error{"Unknown pdu"};
            }
        }
        catch (const std::exception& ex)
        {
            if (deserialization_error_handler)
                deserialization_error_handler(std::string{ex.what()}, command_id, buf);
            close("an exception occurred during deserialization");
            return;
        }

        if (resp.index() != 0 && state_ == state::open && response_handler)
            response_handler(std::move(resp), sequence_number, command_status);
    }

    void consume_request_pdu(command_id command_id, command_status /*unused*/, uint32_t sequence_number, std::span<const uint8_t> buf)
    {
        request req;
        try
        {
            switch (command_id)
            {
                case command_id::enquire_link_req:
                    send_command(command_id::enquire_link_resp, sequence_number);
                    break;
                case command_id::unbind_req:
                    if (state_ == state::open) state_ = state::unbinding;
                    send_command(command_id::unbind_resp, sequence_number);
                    break;
                case command_id::bind_req:
                    req = deserialize<bind_request>(buf, bind_type::bi_direction);
                    break;
                case command_id::stream_req:
                    req = deserialize<stream_request>(buf);
                    break;
                default:
                    throw std::logic_error{"Unknown pdu"};
            }
        }
        catch (const std::exception& ex)
        {
            if (deserialization_error_handler)
                deserialization_error_handler(std::string{ex.what()}, command_id, buf);
            close("an exception occurred during deserialization");
            return;
        }

        if (req.index() != 0 && state_ == state::open && request_handler)
            request_handler(std::move(req), sequence_number);
    }

    // ---------------- Send implementation ----------------
    template<typename PDU>
    void send_impl(const PDU& pdu, uint32_t seq, command_status cst)
    {
        if (state_ != state::open) [[unlikely]]
            return;

        // Serialize PDU body
        std::vector<uint8_t> tmp;
        try {
            serialize_to(&tmp, pdu);
        } catch (...) {
            // Don't mutate queues if serialization fails
            throw;
        }

        const uint32_t total_len_u32 = static_cast<uint32_t>(header_length + tmp.size());
        if (total_len_u32 > max_command_length) [[unlikely]]
            throw std::length_error("PDU exceeds maximum size");

        auto header = serialize_header(total_len_u32, detail::command_id_of(pdu), seq, cst);

        // Build buffer sequence
        std::vector<boost::asio::const_buffer> bufs;
        bufs.emplace_back(boost::asio::buffer(header));
        if (!tmp.empty())
            bufs.emplace_back(boost::asio::buffer(tmp));

        // Try to enqueue into ring (zero-copy path)
        bool ok = send_ring_.try_enqueue_from_buffers(bufs);

        if (!ok)
        {
            // Check fallback buffer limit to prevent unbounded growth
            if (pending_send_buf_.size() + total_len_u32 > max_pending_send_buf) [[unlikely]]
            {
                close("send buffer overflow - connection too slow");
                return;
            }

            // Fallback: append to pending buffer
            pending_send_buf_.insert(pending_send_buf_.end(), header.begin(), header.end());
            if (!tmp.empty())
                pending_send_buf_.insert(pending_send_buf_.end(), tmp.begin(), tmp.end());

            stats_.ring_overflows.fetch_add(1, std::memory_order_relaxed);
            stats_.fallback_sends.fetch_add(1, std::memory_order_relaxed);
        }

        stats_.pdus_sent.fetch_add(1, std::memory_order_relaxed);
        stats_.bytes_sent.fetch_add(total_len_u32, std::memory_order_relaxed);

        // Kick off send if not in progress
        if (!send_in_progress_)
            do_send();
    }

    uint32_t send_command(command_id cid)
    {
        uint32_t seq = next_sequence_number();
        send_command(cid, seq);
        return seq;
    }

    void send_command(command_id cid, uint32_t seq, command_status cst = command_status::rok)
    {
        auto header = serialize_header(static_cast<uint32_t>(header_length), cid, seq, cst);
        std::vector<boost::asio::const_buffer> bufs;
        bufs.emplace_back(boost::asio::buffer(header));

        if (!send_ring_.try_enqueue_from_buffers(bufs))
        {
            // Check fallback buffer limit
            if (pending_send_buf_.size() + header_length > max_pending_send_buf) [[unlikely]]
            {
                close("send buffer overflow - connection too slow");
                return;
            }

            pending_send_buf_.insert(pending_send_buf_.end(), header.begin(), header.end());
            stats_.ring_overflows.fetch_add(1, std::memory_order_relaxed);
            stats_.fallback_sends.fetch_add(1, std::memory_order_relaxed);
        }

        stats_.pdus_sent.fetch_add(1, std::memory_order_relaxed);
        stats_.bytes_sent.fetch_add(header_length, std::memory_order_relaxed);

        if (!send_in_progress_)
            do_send();
    }

    void do_send()
    {
        // Guard against re-entry
        if (send_in_progress_)
            return;

        // If fallback write is in progress, don't start new send
        if (!writing_send_buf_.empty())
            return;

        // Prefer ring buffer (zero-copy path)
        std::array<std::span<const uint8_t>, 2> spans{};
        size_t available = send_ring_.dequeue_scatter_gather(spans, max_send_chunk, /*peek_only=*/true);

        if (available > 0)
        {
            send_in_progress_ = true;

            std::vector<boost::asio::const_buffer> bufs;
            bufs.reserve(2);

            size_t remain = available;
            for (auto &s : spans)
            {
                if (remain == 0) break;
                size_t take = std::min(s.size(), remain);
                if (take > 0)
                    bufs.emplace_back(s.data(), take);
                remain -= take;
            }

            if (bufs.empty()) [[unlikely]]
            {
                send_in_progress_ = false;
                return;
            }

            auto wptr = weak_from_this();
            auto handler = [this, wptr, available](std::error_code ec, size_t bytes_transferred) {
                if (auto self = wptr.lock())
                {
                    self->send_in_progress_ = false;

                    if (ec)
                        return self->close(ec.message());

                    // Consume bytes from ring
                    self->send_ring_.consume(bytes_transferred);

                    // Notify if buffer space available
                    if (self->send_buf_available_handler &&
                        self->send_ring_.space_remaining() > self->send_buf_threshold_)
                    {
                        self->send_buf_available_handler();
                    }

                    // Continue sending if more data available
                    if (self->send_ring_.size() > 0 || !self->pending_send_buf_.empty())
                        boost::asio::post(self->strand_, [self]() { self->do_send(); });
                }
            };

            boost::asio::async_write(
                socket_,
                bufs,
                PINEX_BIND_EXECUTOR(strand_, handler));
            return;
        }

        // Fallback to monolithic pending buffer
        if (!pending_send_buf_.empty())
        {
            send_in_progress_ = true;

            // Swap to writing buffer
            std::swap(writing_send_buf_, pending_send_buf_);

            auto wptr = weak_from_this();
            auto handler = [this, wptr](std::error_code ec, size_t bytes_transferred) {
                if (auto self = wptr.lock())
                {
                    self->send_in_progress_ = false;

                    if (ec)
                        return self->close(ec.message());

                    // Clear written data
                    self->writing_send_buf_.clear();

                    if (self->writing_send_buf_.capacity() < 8192)
                        self->writing_send_buf_.reserve(8192);


                    // Shrink if buffer got too large
                    // if (self->writing_send_buf_.capacity() > 1024 * 1024)
                    // {
                    //     self->writing_send_buf_.shrink_to_fit();
                    //     self->writing_send_buf_.reserve(8192);
                    // }

                    // Notify if buffer space available
                    if (self->send_buf_available_handler &&
                        self->send_ring_.space_remaining() > self->send_buf_threshold_)
                    {
                        self->send_buf_available_handler();
                    }

                    // Continue sending if more data
                    if (self->send_ring_.size() > 0 || !self->pending_send_buf_.empty())
                        boost::asio::post(self->strand_, [self]() { self->do_send(); });
                }
            };

            boost::asio::async_write(
                socket_,
                boost::asio::buffer(writing_send_buf_),
                PINEX_BIND_EXECUTOR(strand_, handler));
        }
    }

    static bool is_response(command_id command_id)
    {
        return static_cast<uint8_t>(command_id) & 0x80;
    }

    static std::tuple<uint32_t, command_id, command_status, uint32_t> deserialize_header(std::span<const uint8_t> buf)
    {
        auto u32 = [](std::span<const uint8_t, 4> b) -> uint32_t {
            return (static_cast<uint32_t>(b[0]) << 24) |
                   (static_cast<uint32_t>(b[1]) << 16) |
                   (static_cast<uint32_t>(b[2]) << 8) |
                   static_cast<uint32_t>(b[3]);
        };

        uint32_t len = u32(buf.subspan<0,4>());
        auto cid = static_cast<pinex::command_id>(buf[4]);
        auto cst = static_cast<pinex::command_status>(buf[5]);
        uint32_t seq = u32(buf.subspan<6,4>());
        return {len, cid, cst, seq};
    }

    static std::array<uint8_t, header_length> serialize_header(uint32_t command_length, command_id command_id, uint32_t sequence_number, command_status command_status)
    {
        std::array<uint8_t, header_length> buf{};
        auto serialize_u32 = [](std::span<uint8_t, 4> b, uint32_t val) {
            b[0] = static_cast<uint8_t>((val >> 24) & 0xFF);
            b[1] = static_cast<uint8_t>((val >> 16) & 0xFF);
            b[2] = static_cast<uint8_t>((val >> 8) & 0xFF);
            b[3] = static_cast<uint8_t>((val >> 0) & 0xFF);
        };
        serialize_u32(std::span{buf}.subspan<0,4>(), command_length);
        buf[4] = static_cast<uint8_t>(command_id);
        buf[5] = static_cast<uint8_t>(command_status);
        serialize_u32(std::span{buf}.subspan<6,4>(), sequence_number);
        return buf;
    }
};

#undef PINEX_EXECUTOR_TYPE
#undef PINEX_BIND_EXECUTOR

} // namespace pa::pinex